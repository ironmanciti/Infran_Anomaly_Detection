{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  신용 카드 이상 거래 탐지 - 전통적 ML 지도학습\n",
    "\n",
    "## Logistic Regression, Random Forest, KNN + Over/Under-sampling\n",
    "\n",
    "- 극도로 편향된 신용카드 사기 거래 data 분류 - 지도학습 모델  \n",
    "\n",
    "- Highly Imbalanced Dataset - 284,807 거래 건 중 492 개의 사기거래 존재\n",
    "\n",
    "\n",
    "- [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud) - Kaggle\n",
    "\n",
    "\n",
    "- Highly Imbalanced Dataset - dataset는 2013 년 9 월 유럽 카드 소지자 신용 카드 거래로 만들었습니다. 이 dataset는 2 일 동안 발생한 거래를 보여 주며, 284,807 건의 거래 중 492 건의 fraud가 있습니다. 데이터세트는 매우 불균형하며 포지티브 클래스(사기)는 모든 거래의 0.172 %를 차지합니다.\n",
    "\n",
    "\n",
    "- 이 dataset는 PCA 변환의 결과인 숫자 입력 변수만 포함합니다. 기밀 유지 문제로 인해 데이터에 대한 원래 feature와 추가 background 정보는 제공되지 않습니다. 특성 V1, V2, ... V28은 PCA로 얻은 principal component이며 PCA로 변환되지 않은 유일한 기능은 'Time' 과 'Amount' 입니다. 'Time' 특성은 각 트랜잭션과 데이터 세트의 첫 번째 트랜잭션 사이에 경과된 시간(초) 입니다. 'Amount' 특성은 거래금액 입니다.  'Class'는 사기의 경우 1, 그렇지 않으면 0 입니다.\n",
    "\n",
    "\n",
    "- 클래스 불균형 비율이 주어지면 Area Under the Precision-Recall Curve (AUPRC)을 사용하여 정확도를 측정하는 것이 좋습니다. 불균형 data 분류에는 confusion matrix 정확도가 의미가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "trailing comma not allowed without surrounding parentheses (211231286.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m\u001b[0m\n\u001b[1;33m    from sklearn.metrics import  accuracy_score, precision_score,\u001b[0m\n\u001b[1;37m                                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m trailing comma not allowed without surrounding parentheses\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import  accuracy_score, precision_score, recall_score, \\\n",
    "                            roc_curve, roc_auc_score\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (12, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Credit Card Fraud dataset 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = df['Class'].value_counts().values.tolist()\n",
    "total = neg + pos\n",
    "print(f'Total 건수: {total}\\nPositive 건수/비율: {pos} ({pos/total*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 전처리 \n",
    "\n",
    "- 2 일 동안의 data가 00:00:00 부터 발생했으므로 Time을 일중 시간으로 변경 : time / 3600 초 % 24 시간  \n",
    "- Amount column 은 편차가 크므로 log-scale 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = df.copy()\n",
    "\n",
    "# Time 을 일중 시간으로 변환\n",
    "cleaned_df.loc[:, \"Time\"] = \\\n",
    "cleaned_df.loc[:, \"Time\"].apply(lambda x : x / 3600 % 24) \n",
    "\n",
    "# Amount column 은 편차가 크므로 log-scale 로 변환\n",
    "eps=0.001     \n",
    "cleaned_df['Amount'] = np.log(cleaned_df.pop('Amount') + eps)\n",
    "\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3))\n",
    "df['Amount'].plot(kind='hist', ax=ax1)\n",
    "cleaned_df['Amount'].plot(kind='hist', ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(cleaned_df.pop('Class'))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cleaned_df.values\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 을 Training 과 Test set 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, \n",
    "                         test_size=0.5, random_state=0, stratify=labels)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"전체 data의 positive 건수 : \", Counter(labels))\n",
    "print(\"Train set 의 positive 건수 : \", Counter(y_train))\n",
    "print(\"Test set 의 positive 건수 : \", Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Logistic Regression model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr  = LogisticRegression(random_state=0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 모델을 이용하여 Test set 예측\n",
    "- predict_proba() - class 의 probability 반환 ([negative 확률, positive 확률])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "print(\"Test set positive 건수 = \", sum(y_test))\n",
    "print(\"Predicted positive 건수 = \", sum(y_pred))\n",
    "print(\"accuracy = {:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix 를 이용한 model 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_test, y_pred_proba, threshold):\n",
    "    \n",
    "    y_pred = y_pred_proba > threshold\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"f1 score:\", f1_score(y_test, y_pred))\n",
    "    print(\"Accuracy\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision\", precision_score(y_test, y_pred))\n",
    "    print(\"Recall\", recall_score(y_test, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix (threshold>{:.2f}) '.format(threshold))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud 거래를 잡아내는 것이 목적이므로, fraud case 를 놓치지 않으려면 recall 을 높인다.\n",
    "\n",
    "이를 위해 threshold 를 0.2 로 조정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred_prob, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 불균형 데이터에 대한 Resampling 기법 적용\n",
    "     \n",
    "- minority class를 oversample 하고 majority class를 undersample  \n",
    "- minority data 의 수(비율)를 증가시켜 새로이 fitting  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소수 class 비율이 10%가 되도록 소수 class를 oversample  \n",
    "- `sampling_strategy` parameter는 리샘플링 후 다수 클래스에 대한 소수 클래스의  비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = RandomOverSampler(sampling_strategy=0.1)\n",
    "X, y = over.fit_resample(X_train, y_train)\n",
    "X.shape, y.shape, Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 소수 class 비율이 50%가 되도록 다수 class를 undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X, y = under.fit_resample(X, y)\n",
    "X.shape, y.shape, Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2.  Logistic Regression model 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_lr = LogisticRegression(max_iter=1000, random_state=0)\n",
    "re_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습된 모델을 이용하여 Test set 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = re_lr.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "print(\"Test set positive 건수 = \", sum(y_test))\n",
    "print(\"Predicted positive 건수 = \", sum(y_pred))\n",
    "print(\"accuracy = {:.5f}\".format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oversample + undersample 기법 적용 결과 precision(positive로 예측한 내용 중에, 실제 Positive의 비율)은 크게 낮아지고,  recall(전체 positive 데이타 중에서 positive로 분류한 비율)이 높아짐."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RandomForest model을 이용한 분류\n",
    "\n",
    "oversample + undersample 한 data 를  random forest model을 이용하여 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, \n",
    "                            max_depth=12, min_samples_leaf=50,\n",
    "                            min_samples_split=6, n_jobs=-1, verbose=1)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "print(\"Test set의 positive 건수 = \", sum(y_test))\n",
    "print(\"Prediction의 positive  건수 = \", sum(y_pred))\n",
    "print(\"accuracy = {:.5f}\".format(sum(y_pred == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Nearest Neighbors model을 이용한 분류\n",
    "\n",
    "oversample + undersample 한 data를  K-Nearest Neighbors model을 이용하여 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15, weights='uniform')\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_prob = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred = y_pred_prob > 0.5\n",
    "\n",
    "print(\"Test set의 positive 건수 = \", sum(y_test))\n",
    "print(\"Prediction의 positive  건수 = \", sum(y_pred))\n",
    "print(\"accuracy = {:.5f}\".format(sum(y_pred == y_test) / len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred_prob, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC(Receiver Operating Characteristic) curve 시각화로 모델 설능 비교\n",
    "``` fpr, tpr, _ = roc_curve(y_true, y_score) ```\n",
    "- fpr - false positive rates,  tpr - true positive rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(labels, predictions)\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    \n",
    "    plt.plot(100*fpr, 100*tpr, label=f\"{name}={auc:.5f}\", \n",
    "             linewidth=2, **kwargs)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.xlabel('FPR [%]')\n",
    "    plt.ylabel('TPR [%]')\n",
    "    plt.xlim([-0.5,40])\n",
    "    plt.ylim([80,100.5])\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(8, 6)\n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = lr.predict_proba(X_test)[:,1]\n",
    "plot_roc(\"LogisticRegression\", y_test, y_prob, \n",
    "         color='blue', linestyle='--')\n",
    "\n",
    "y_prob = re_lr.predict_proba(X_test)[:,1]\n",
    "plot_roc(\"over+under sampling(LogisticRegression)\", y_test, y_prob, color='red', linestyle='--')\n",
    "\n",
    "y_prob = rf.predict_proba(X_test)[:,1]\n",
    "plot_roc(\"over+under sampling(RandomForest)\", y_test, y_prob, color='green', linestyle='--')\n",
    "\n",
    "y_prob = knn.predict_proba(X_test)[:,1]\n",
    "plot_roc(\"over+under sampling(K-Nearest Neighbors)\", y_test, y_prob, color='yellow', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IE (Integrated Error)\n",
    "\n",
    "- FRR : False Rejection Rate  \n",
    "\n",
    "- FAR : False Acceptance Rate\n",
    "\n",
    "FRR = FNR = FN/(FN + TN)  \n",
    "FAR = FPR = FP/(FP + FN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "y_prob = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "fnr = 1 - tpr\n",
    "plt.plot(fnr, fpr, label='LogisticRegressiong')\n",
    "\n",
    "y_prob = re_lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "fnr = 1 - tpr\n",
    "plt.plot(fnr, fpr, label='LogisticRegression over+undersampling')\n",
    "\n",
    "y_prob = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "fnr = 1 - tpr\n",
    "plt.plot(fnr, fpr, label='RandomForest over+undersampling')\n",
    "\n",
    "y_prob = knn.predict_proba(X_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "fnr = 1 - tpr\n",
    "plt.plot(fnr, fpr, label='K-Nearest Neighbors over+undersampling')\n",
    "\n",
    "plt.title(\"Integrated Error\")\n",
    "plt.xlabel('False Rejection Rate')\n",
    "plt.ylabel('Flase Acceptance Rate')\n",
    "plt.xlim([0, 0.4])\n",
    "plt.ylim([-0.05, 0.4])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
